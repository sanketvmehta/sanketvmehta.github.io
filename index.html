<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1WFQ5GQZ99"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-1WFQ5GQZ99');
    </script>


  <title>Sanket Vaibhav Mehta</title>
  
  <meta name="author" content="Sanket Vaibhav Mehta">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!--<link rel="icon" type="image/png" href="images/icon_dp.jpg">-->
    <link rel="icon" type="image/png" href="images/svm.jpg">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:1%;padding-top:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sanket Vaibhav Mehta [SVM]</name>
              </p>
              <p>I am a <a href="https://research.google/people/sanket-vaibhav-mehta/">Research Scientist at Google Research</a>, focusing on continual lifelong learning and unlearning from non-stationary environments!</p>

              <p>I received my Ph.D. from <a href="https://www.lti.cs.cmu.edu/">Language Technologies Institute (LTI)</a> at <a href="https://www.cs.cmu.edu/">School of Computer Science, Carnegie Mellon University</a>, where I was advised by <a href="https://strubell.github.io/">Emma Strubell</a>.
              Before that I obtained a Master's degree (2019) from the LTI where I was advised by <a href="https://www.cs.cmu.edu/~jgc">Jaime Carbonell</a> and <a href="https://www.cs.cmu.edu/~bapoczos/">Barnabás Póczos</a>.
              </p>

              <p>
                Before joining CMU, I worked as a member of the research staff at <a href="https://research.adobe.com/">Big Data Research Lab, Adobe Research</a> (2015-17) where I worked on designing algorithms for identifying data-driven geo-fences to assist Adobe’s digital marketing offering. </p>

              <p>I graduated from <a href="https://iitr.ac.in/">Indian Institute of Technology Roorkee</a> with a B.Tech in Computer Science (2011-15) and a President's Gold Medal. </p>
              <p style="text-align:center">
                <a href="mailto:sanketvmehta@google.com">Email</a> &nbsp/&nbsp
                <a href="data/CV_Sanket_Vaibhav_Mehta.pdf">CV</a> &nbsp/&nbsp
                <!--<a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com/citations?user=H4pn-ogAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/sanketvmehta">X</a> &nbsp/&nbsp
<!--                <a rel="me" href="https://sigmoid.social/@svm">Mastodon</a> &nbsp/&nbsp-->
                <a href="https://github.com/sanketvmehta/">GitHub</a>

                  <!--&nbsp/&nbsp-->
                <!--<a href="https://www.instagram.com/sanketvmehta/">Food@Instagram :)</a>-->
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:40%">
              <a href="images/svm.jpg"><img style="max-width:100%" alt="profile photo" src="images/svm.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                <!--I'm interested in machine learning, natural language processing and optimization with a specific focus on incremental learning and learning to learn.                -->
                  I'm interested in machine learning, natural language processing and optimization with a specific focus on learning from limited labeled data, multiple tasks, non-stationary data distributions (Continual/ Lifelong Learning, Transfer Learning, Meta Learning, Multi-Task Learning, Modular Learning).
              </p>
                <p>
                    My <a href="https://doi.org/10.1184/R1/24992883.v1">doctoral thesis</a> focuses on designing efficient lifelong learning systems that alleviate catastrophic forgetting of previously learned knowledge and facilitate continual learning of new tasks. Inspired by biological learning
                    processes and progress in deep learning, my work injects appropriate inductive biases into the three main components of data-driven machine learning:
                    model (<a href="https://openreview.net/forum?id=ntUmktUfZg">architecture</a> & <a href="https://jmlr.org/papers/v24/22-0496.html">initialization</a>),
                    training (<a href="https://aclanthology.org/2020.emnlp-main.39">objective</a> & <a href="https://jmlr.org/papers/v24/22-0496.html">optimization</a>), and
                    data (<a href="https://aclanthology.org/2023.emnlp-main.510">limited labeled</a> & <a href="https://openreview.net/forum?id=Xazhn0JoNx">unlabeled</a>).
                </p>
            </td>
          </tr>
        </tbody></table>

        <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:1%;width:100%;vertical-align:middle">
                  <heading>Latest News</heading>
                    <ul>
<!--                    <li><strong> [Aug. 28, 2023] </strong> &nbsp;-->
<!--                    <a href="https://jmlr.org/papers/v24/22-0496.html">An Empirical Investigation of the Role of Pre-training in Lifelong Learning</a> will be presented at NeurIPS 2023 Journal-to-Conference Track!</li>-->
<!--                    <br>-->
                    <li><strong> [Feb. 9, 2024] </strong> &nbsp;
                      My doctoral thesis is available online on <a href="https://doi.org/10.1184/R1/24992883.v1">CMU KiltHub</a>!</li>
                    <br>
                    <li><strong> [Dec. 11, 2023] </strong> &nbsp;
                      I'm attending <a href="https://nips.cc/Conferences/2023">NeurIPS'23</a> to present our <a href="https://jmlr.org/papers/v24/22-0496.html">JMLR</a> and <a href="https://openreview.net/forum?id=Xazhn0JoNx">Making Scalable Meta Learning Practical</a> papers!</li>
                    <br>
                    <li><strong> [Dec. 4, 2023] </strong> &nbsp;
                      I'm attending <a href="https://2023.emnlp.org/">EMNLP'23</a> to present our <a href="https://aclanthology.org/2023.emnlp-main.510">DSI++</a> paper!</li>
                    <br>
                    <li><strong> [Nov, 2023] </strong> &nbsp;
                      Excited to join <a href="https://research.google/">Google Research</a> as a full-time researcher.</li>
                    <br>
                    <li><strong> [Nov. 30, 2023] </strong> &nbsp;
                      I successfully defended my doctoral thesis! (Thesis committee: <a href="https://strubell.github.io/">Emma Strubell</a>, <a href="https://wwcohen.github.io/">William Cohen</a>, <a href="https://www.cs.cmu.edu/~aditirag/">Aditi Raghunathan</a>, <a href="https://dyogatama.github.io/">Dani Yogatama</a>)</li>
                    <br>
                    <li><strong> [Oct. 7, 2023] </strong> &nbsp;
                      <a href="https://aclanthology.org/2023.emnlp-main.510">DSI++</a> paper accepted at EMNLP 2023!</li>
                    <br>
                    <li><strong> [Sept. 21, 2023] </strong> &nbsp;
                      <a href="https://openreview.net/forum?id=Xazhn0JoNx">Making Scalable Meta Learning Practical</a> paper accepted at NeurIPS 2023! <a href="https://twitter.com/sangkeun_choe/status/1716476614257836123">TL;DR</a>!</li>
                    <br>
                    <li><strong> [Jul. 4, 2023] </strong> &nbsp;
                    <a href="https://jmlr.org/papers/v24/22-0496.html">An Empirical Investigation of the Role of Pre-training in Lifelong Learning</a> paper accepted at JMLR 2023 and will be presented at NeurIPS 2023 Journal-to-Conference Track! <a href="https://twitter.com/sanketvmehta/status/1699427024396308845">TL;DR</a>!</li>
                    <br>
                    <li><strong> [Jun. 23, 2023] </strong> &nbsp;
                    <a href="https://openreview.net/forum?id=avmAZiWarU">Conditional Diffusion Replay for Continual Learning in Medical Settings</a> paper accepted at Workshop on Challenges in Deployable Generative AI, ICML 2023!</li>
                    <br>
                    <li><strong> [Jun. 19, 2023] </strong> &nbsp;
                    <a href="https://drive.google.com/file/d/1Y8ippeKGzCA9uVxmIkHE4xTJky76eh7-/view">Adapting to Gradual Distribution Shifts with Continual Weight Averaging</a> paper accepted at Workshop on High-dimensional Learning Dynamics, ICML 2023!</li>
                    <br>
                    <li><strong> [Jan. 23, 2023] </strong> &nbsp;
                    I proposed my doctoral thesis! (Thesis committee: <a href="https://strubell.github.io/">Emma Strubell</a>, <a href="https://wwcohen.github.io/">William Cohen</a>, <a href="https://www.cs.cmu.edu/~aditirag/">Aditi Raghunathan</a>, <a href="https://dyogatama.github.io/">Dani Yogatama</a>)</li>
                    <br>
                    <li><strong> [Dec. 19, 2022] </strong> &nbsp;
                    <a href="https://arxiv.org/abs/2212.09744">DSI++</a> paper is out! <a href="https://twitter.com/YiTayML/status/1605097291542470656">TL;DR</a>!</li>
                    <br>
                    <li><strong> [Nov. 28, 2022] </strong> &nbsp;
                    I'm attending <a href="https://nips.cc/Conferences/2022">NeurIPS'22</a>!</li>
                    <br>
                    <li><strong> [Oct. 6, 2022] </strong> &nbsp;
                      <a href="https://aclanthology.org/2022.findings-emnlp.361">Train Flat, Then Compress</a> paper accepted at Findings of EMNLP 2022!</li>
                    <br>
                    <li><strong> [July. 10, 2022] </strong> &nbsp;
                      <a href="https://arxiv.org/abs/2207.04354">An Introduction to Lifelong Supervised Learning</a> primer is out!</li>
                    <br>
                    <li><strong> [May. 23, 2022] </strong> &nbsp;
                        Excited to start summer internship with <a href="https://www.yitay.net/">Yi Tay</a> and <a href="https://research.google/people/106128/">Jai Gupta</a> at <a href="https://research.google/">Google Research</a>!</li>
                    <br>
                    <li><strong> [Feb. 24, 2022] </strong> &nbsp;
                      <a href="https://aclanthology.org/2022.acl-long.289/">Compositional Generalization for Data-to-Text Generation</a> paper accepted at ACL 2022!</li>
                    <br>
                    <li><strong> [Jan. 20, 2022] </strong> &nbsp;
                      <a href="https://openreview.net/forum?id=Vzh1BFUCiIX">ExT5: Extreme Multi-Task Scaling</a> paper accepted at ICLR 2022!</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:1%;width:100%;vertical-align:middle">
                  <heading>Publications</heading>
                </td>
              </tr>
            </tbody>
      </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/thesis.png" alt="clean-usnob" width="250" height="110"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://doi.org/10.1184/R1/24992883.v1">
                <papertitle>Efficient Lifelong Learning in Deep Neural Networks: Optimizing Architecture, Training, and Data</papertitle>
              </a>
              <br>
                <strong>Sanket Vaibhav Mehta</strong>
                <br>
              <em>PhD thesis, Carnegie Mellon University</em>, 2023
              <br>
                 <a href="data/Thesis.bib">bibtex</a> /
                 <a href="https://twitter.com/sanketvmehta/status/1731847891386298440">tweet</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/dsipp.png" alt="clean-usnob" width="250" height="110"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://aclanthology.org/2023.emnlp-main.510">
                <papertitle>DSI++: Updating Transformer Memory with New Documents</papertitle>
              </a>
              <br>
                <strong>Sanket Vaibhav Mehta</strong>,
                Jai Gupta,
                Yi Tay,
                Mostafa Dehghani,
                Vinh Q. Tran,
                Jinfeng Rao,
                Marc Najork,
                Emma Strubell,
                Donald Metzler
              <br>
              <em>EMNLP</em>, 2023
              <br>
                 <a href="data/DSIpp.bib">bibtex</a> /
                 <a href="https://twitter.com/YiTayML/status/1605097291542470656">tweet</a>
<!--                /-->
<!--                <a href="https://sigmoid.social/@svm/109549897715641270">mastodon</a>-->

              <br>
            </td>
          </tr>


          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/losscontour.png" alt="clean-usnob" width="250" height="110"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://jmlr.org/papers/v24/22-0496.html">
                <papertitle>An Empirical Investigation of the Role of Pre-training in Lifelong Learning</papertitle>
              </a>
              <br>
                <strong>Sanket Vaibhav Mehta</strong>,
                Darshan Patil,
                Sarath Chandar,
                Emma Strubell
              <br>
                <em>Journal of Machine Learning Research</em>, 2023
                <br>
              <!--<br>-->
              <!--<em>ICML Theory and Foundation of Continual Learning Workshop</em>, 2021 (<a href="https://icml.cc/Conferences/2021/ScheduleMultitrack?event=8348">Spotlight</a>)-->
              <!--<br>-->
                 <a href="data/PretrainLLL.bib">bibtex</a> /
                 <a href="https://github.com/sanketvmehta/lifelong-learning-pretraining-and-sam">code</a> /
                <a href="https://twitter.com/sanketvmehta/status/1699427024396308845">tweet</a>
              <br>
            </td>
          </tr>


          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/sama.png" alt="clean-usnob" width="250" height="110"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=Xazhn0JoNx">
                <papertitle>Making Scalable Meta Learning Practical</papertitle>
              </a>
              <br>
                Sang Keun Choe,
                <strong>Sanket Vaibhav Mehta</strong>,
                Hwijeen Ahn,
                Willie Neiswanger,
                Pengtao Xie,
                Emma Strubell,
                Eric Xing
              <br>
                <em>NeurIPS</em>, 2023
                <br>
                 <a href="data/SAMA.bib">bibtex</a> /
                 <a href="https://github.com/leopard-ai/betty">code</a> /
                <a href="https://twitter.com/sangkeun_choe/status/1716476614257836123">tweet</a>
              <br>
            </td>
          </tr>


          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/trainflatglue.png" alt="clean-usnob" width="250" height="110"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://aclanthology.org/2022.findings-emnlp.361">
                <papertitle>Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models
</papertitle>
              </a>
              <br>
                Clara Na,
                <strong>Sanket Vaibhav Mehta</strong>,
                Emma Strubell
              <br>
              <em>EMNLP Findings</em>, 2022
              <br>
                 <a href="data/TRAINFLAT2022.bib">bibtex</a> /
                 <a href="https://github.com/clarana/train-flat-compress">code</a> /
                 <a href="https://twitter.com/claranahhh/status/1585427169278164992">tweet</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/lllprimer.png" alt="clean-usnob" width="250" height="110"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.04354">
                <papertitle>An Introduction to Lifelong Supervised Learning</papertitle>
              </a>
              <br>
                Shagun Sodhani,
                Mojtaba Faramarzi,
                <strong>Sanket Vaibhav Mehta</strong>,
                Pranshu Malviya,
                Mohamed Abdelsalam,
                Janarthanan Janarthanan,
                Sarath Chandar
              <br>
              <em>arXiv</em>, 2022
              <br>
                 <a href="data/LLLPrimer.bib">bibtex</a> /
                 <a href="https://twitter.com/apsarathchandar/status/1547035541149040641">tweet</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/ruleeng.png" alt="clean-usnob" width="250" height="110"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://aclanthology.org/2022.acl-long.289/">
                <papertitle>Improving Compositional Generalization with Self-Training for Data-to-Text Generation</papertitle>
              </a>
              <br>
                <strong>Sanket Vaibhav Mehta</strong>,
                Jinfeng Rao,
                Yi Tay,
                Mihir Kale,
                Ankur Parikh,
                Emma Strubell
              <br>
              <em>ACL</em>, 2022
              <br>
              <a href="data/COMPGENACL2022.bib">bibtex</a> /
                <a href="https://github.com/google-research/google-research/tree/master/compgen_d2t">code</a> /
               <a href="data/COMPGENACL2022.pdf">poster</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/ext5.png" alt="clean-usnob" width="250" height="110"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=Vzh1BFUCiIX">
                <papertitle>ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning</papertitle>
              </a>
              <br>
                Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, <strong>Sanket Vaibhav Mehta</strong>,
                Honglei Zhuang, Vinh Q. Tran, Dara Bahri, Jianmo Ni, Jai Gupta, Kai Hui, Sebastian Ruder, Donald Metzler
              <br>
              <em>ICLR</em>, 2022
              <br>
              <a href="data/ExT5ICLR2022.bib">bibtex</a> /
                <a href="https://youtu.be/FbRcbM4T-50">press</a> /
                <a href="https://twitter.com/YiTayML/status/1463197481173278727">tweet</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/losscontour.png" alt="clean-usnob" width="250" height="110"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://jmlr.org/papers/v24/22-0496.html">
                <papertitle>An Empirical Investigation of the Role of Pre-training in Lifelong Learning</papertitle>
              </a>
              <br>
                <strong>Sanket Vaibhav Mehta</strong>,
                Darshan Patil,
                Sarath Chandar,
                Emma Strubell
              <br>
              <em>ICML Theory and Foundation of Continual Learning Workshop</em>, 2021 (<a href="https://icml.cc/Conferences/2021/ScheduleMultitrack?event=8348">Spotlight</a>)
              <br>
                 <a href="data/PretrainLLL.bib">bibtex</a> /
                 <a href="https://github.com/sanketvmehta/lifelong-learning-pretraining-and-sam">code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="display:block;padding:5px;width:30%;margin: auto;"><img src="images/metambpa1.png" alt="clean-usnob" width="130" height="130"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://aclanthology.org/2020.emnlp-main.39/">
                <papertitle>Efficient Meta Lifelong-Learning with Limited Memory</papertitle>
              </a>
              <br>
                <strong>Sanket Vaibhav Mehta</strong>*,
                Zirui Wang*,
                Barnabás Póczos,
                Jaime Carbonell
              <br>
              <em>EMNLP</em>, 2020
              <br>
              <a href="data/MetaMBPA.bib">bibtex</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/rhymgan.png" alt="clean-usnob" width="250" height="110"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://aclanthology.org/D19-1621/">
                <papertitle>Learning Rhyming Constraints using Structured Adversaries</papertitle>
              </a>
              <br>
                Harsh Jhamtani,
                <strong>Sanket Vaibhav Mehta</strong>,
                Jaime Carbonell,
                Taylor Berg-Kirkpatrick
              <br>
              <em>EMNLP</em>, 2019
              <br>
              <a href="data/RhymGanEMNLP2019.bib">bibtex</a> /
              <a href="https://github.com/harsh19/Structured-Adversary">code</a> /
              <a href="https://drive.google.com/file/d/14etRmaz6i9gOTRa6MXtrRxY9BVKE8ppu/view">poster</a>
              <br>
            </td>
          </tr>
          
          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/gbi.png" alt="clean-usnob" width="230" height="120"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/4316">
                <papertitle>Gradient-Based Inference for Networks with Output Constraints
</papertitle>
              </a>
              <br>
              Jay-Yoon Lee,
              <strong>Sanket Vaibhav Mehta</strong>,
              Michael Wick,
              Jean-Baptiste Tristan,
              Jaime Carbonell
              <br>
              <em>AAAI</em>, 2019
              <br>
              <a href="data/GBIAAAI2019.bib">bibtex</a> /
              <a href="https://github.com/sanketvmehta/gradient-based-inference">code</a>
              <br>
            </td>
          </tr>
          
          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/sslsrl.png" alt="clean-usnob" width="230" height="120"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://www.aclweb.org/anthology/D18-1538/">
                <papertitle>Towards Semi-Supervised Learning for Deep Semantic Role Labeling
</papertitle>
              </a>
              <br>
              <strong>Sanket Vaibhav Mehta</strong>*,
              Jay-Yoon Lee*,
              Jaime Carbonell
              <br>
              <em>EMNLP</em>, 2018
              <br>
              <a href="data/SSLSRLEMNLP2018.bib">bibtex</a> /
              <a href="https://github.com/sanketvmehta/ssl-deep-srl">code</a> /
              <a href="data/SSLSRLEMNLP2018.pdf">poster</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/humanactivity.png" alt="clean-usnob" width="230" height="120"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/10.1145/3161201">
                <papertitle>An LSTM Based System for Prediction of Human Activities with Durations
</papertitle>
              </a>
              <br>
              Kundan Krishna,
              Deepali Jain,
              <strong>Sanket Vaibhav Mehta</strong>,
              Sunav Choudhary
              <br>
              <em>IMWUT</em>, 2017
              <br>
              <a href="data/LSTMIMWUT2017.bib">bibtex</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:1%;width:30%;vertical-align:middle"><img src="images/fastxml.gif" alt="clean-usnob" width="230" height="120"></td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-319-57454-7_14">
                <papertitle>Preventing Inadvertent Information Disclosures via Automatic Security Policies
</papertitle>
              </a>
              <br>
              Tanya Goyal,
              <strong>Sanket Vaibhav Mehta</strong>,
              Balaji Vasan Srinivasan
              <br>
              <em>PAKDD</em>, 2017
              <br>
              <a href="data/DRMPAKDD2017.bib">bibtex</a>
              <br>
            </td>
          </tr>

          <!--<tr>-->
            <!--<td style="padding:1%;width:30%;vertical-align:middle"><img src="images/star.gif" alt="clean-usnob" width="230" height="120"></td>-->
            <!--<td style="padding:20px;width:70%;vertical-align:middle">-->
              <!--<a href="https://link.springer.com/chapter/10.1007/978-3-319-26190-4_19">-->
                <!--<papertitle>Improving Marketing Interactions by Mining Sequence</papertitle>-->
              <!--</a>-->
              <!--<br>-->
              <!--<strong>Sanket Vaibhav Mehta</strong>*,-->
              <!--<a href="https://research.adobe.com/person/ritwik-sinha/">Ritwik Sinha</a>*,-->
              <!--<a href="https://www.linkedin.com/in/tapanbohra">Tapan Bohra</a>*,-->
              <!--<a href="https://aditk2.web.engr.illinois.edu/">Adit Krishnan</a>*-->
              <!--<br>-->
              <!--<em>WISE</em>, 2015-->
              <!--<br>-->
              <!--<a href="data/STARWISE2015.bib">bibtex</a>-->
              <!--<br>-->
            <!--</td>-->
          <!--</tr>-->

        </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Issued Patents</heading>
            </td>
            </tr>

            <tr>
            <td style="padding-left:1%;width:100%;vertical-align:middle">
              <a href="https://patentimages.storage.googleapis.com/eb/7b/89/8384d9edc4cb89/US9838843.pdf"> <papertitle>1. Generating data-driven geo-fences (US 9,838,843)</papertitle></a>
            </td>
            </tr>

            <tr>
            <td style="padding-left:1%;width:100%;vertical-align:middle">
              <a href="https://patentimages.storage.googleapis.com/73/c3/81/2693bd5c12ccc4/US10102191.pdf"> <papertitle>2. Propagation of changes in master content to variant content (US 10,102,191)
</papertitle></a>
            </td>
            </tr>

            <tr>
            <td style="padding-left:1%;width:100%;vertical-align:middle">
              <a href="https://patentimages.storage.googleapis.com/90/0c/0a/e033464a2a35ae/US10489498.pdf"> <papertitle>3. Digital document update (US 10,489,498)
</papertitle></a>
            </td>
            </tr>

            <tr>
            <td style="padding-left:1%;width:100%;vertical-align:middle">
              <a href="https://patentimages.storage.googleapis.com/e3/1c/c4/c46ee653c1fddc/US10783262.pdf"> <papertitle>4. Tagging documents with security policies (US 10,783,262)</papertitle></a>
            </td>
            </tr>

            <tr>
            <td style="padding-left:1%;width:100%;vertical-align:middle">
              <a href="https://patentimages.storage.googleapis.com/de/30/88/b7a367ffdaf44a/US10846466.pdf"> <papertitle>5. Digital document update using static and transient tags (US 10,846,466)
</papertitle></a>
            </td>
            </tr>

            <tr>
            <td style="padding-left:1%;width:100%;vertical-align:middle">
              <a href="https://patentimages.storage.googleapis.com/10/77/03/f75a6ebd98f188/US11086646.pdf"> <papertitle>6. Tenant-side detection, classification, and mitigation of noisy-neighbor-induced performance degradation (US 11,086,646)
</papertitle></a>
            </td>
            </tr>

            <tr>
            <td style="padding-left:1%;width:100%;vertical-align:middle">
              <a href="https://patentimages.storage.googleapis.com/c3/cb/ff/78ca0fa16b2b03/US11756058.pdf"> <papertitle>7. Intelligent customer journey mining and mapping (US 11,756,058)
</papertitle></a>
            </td>
            </tr>

        </tbody></table>

        <!--<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>-->
          <!--<tr>-->
            <!--<td>-->
              <!--<heading>Service</heading>-->
            <!--</td>-->
          <!--</tr>-->
        <!--</tbody></table>-->
        <!--<table width="100%" align="center" border="0" cellpadding="20"><tbody>-->
          <!--<tr>-->
            <!--<td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>-->
            <!--<td width="75%" valign="center">-->
              <!--<a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>-->
              <!--<br>-->
              <!--<br>-->
              <!--<a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>-->
            <!--</td>-->
          <!--</tr>-->
          <!--<tr>-->
            <!--<td style="padding:20px;width:25%;vertical-align:middle">-->
              <!--<img src="images/cs188.jpg" alt="cs188">-->
            <!--</td>-->
            <!--<td width="75%" valign="center">-->
              <!--<a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>-->
              <!--<br>-->
              <!--<br>-->
              <!--<a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>-->
              <!--<br>-->
              <!--<br>-->
              <!--<a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>-->
            <!--</td>-->
          <!--</tr>-->
        <!--</tbody></table>-->
        <br><br>
        Based on <a href="https://jonbarron.info/">Jon Barron's</a> website.
      </td>
    </tr>
  </table>

</body>

</html>
